architecture: RetinaNet
pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_cos_pretrained.pdparams

#### Model ####

RetinaNet:
  backbone: ResNet
  neck: FPN
  head: RetinaHead

ResNet:
  depth: 50
  variant: b
  norm_type: bn
  freeze_at: 0
  return_idx: [1,2,3]
  num_stages: 4

FPN:
  out_channel: 256
  spatial_scales: [0.125, 0.0625, 0.03125]
  extra_stage: 2
  has_extra_convs: true
  use_c5: false

RetinaHead:
  num_classes: 80
  prior_prob: 0.01
  nms_pre: 1000
  conv_feat:
    name: FCOSFeat
    feat_in: 256
    feat_out: 256
    num_convs: 4
    norm_type: null
    use_dcn: false
  anchor_generator:
    name: RetinaAnchorGenerator
    octave_base_scale: 4
    scales_per_octave: 3
    aspect_ratios: [0.5, 1.0, 2.0]
    strides: [8.0, 16.0, 32.0, 64.0, 128.0]
  loss_class:
    name: GHMCLoss
    bins: 30
    momentum: 0.75
    use_sigmoid: true
    loss_weight: 1.0
  loss_bbox:
    name: GHMRLoss
    mu: 0.02
    bins: 10
    momentum: 0.7
    loss_weight: 10.0
  bbox_assigner:
    name: RetinaBBoxAssigner
    fg_thresh: 0.5
    bg_thresh: 0.4
    allow_low_quality: true
  nms:
    name: MultiClassNMS
    nms_top_k: 1000
    keep_top_k: 100
    score_threshold: 0.05
    nms_threshold: 0.5



#### Dataset ####

metric: COCO
num_classes: 80

TrainDataset:
  !COCODataSet
    image_dir: train2017
    anno_path: annotations/instances_train2017.json
    dataset_dir: dataset/coco
    data_fields: ['image', 'gt_bbox', 'gt_class']

EvalDataset:
  !COCODataSet
    image_dir: val2017
    anno_path: annotations/instances_val2017.json
    dataset_dir: dataset/coco

TestDataset:
  !ImageFolder
    anno_path: annotations/instances_val2017.json


#### Reader ####

worker_num: 2
TrainReader:
  sample_transforms:
  - Decode: {}
  - RandomFlip: {prob: 0.5}
  - Resize: {target_size: [800, 1333], keep_ratio: true, interp: 1}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 2
  shuffle: true
  drop_last: true
  use_process: true
  collate_batch: false


EvalReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 1, target_size: [800, 1333], keep_ratio: True}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 2
  shuffle: false


TestReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 1, target_size: [800, 1333], keep_ratio: True}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 1
  shuffle: false



#### Optimizer ####

epoch: 12

LearningRate:
  base_lr: 0.005
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones: [8, 11]
  - !LinearWarmup
    start_factor: 0.001
    steps: 500

OptimizerBuilder:
  clip_grad_by_norm: 35
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0001
    type: L2


#### Runtime ####

use_gpu: true
log_iter: 100
save_dir: output
snapshot_epoch: 1
print_flops: false




find_unused_parameters: True
